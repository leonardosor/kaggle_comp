{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmdarima import model_selection\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import rmse, aic\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Preprocess the data (assuming the date column is named 'date' and the value column is named 'value')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "# Ensure the directory for saving models exists\n",
    "#os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_plot(data['num_sold'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "blind = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series, signif=0.05,  verbose=False):\n",
    "    \n",
    "    series.dropna(inplace = True)\n",
    "    result = adfuller(series.values)\n",
    "\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n",
    "        print(\"\\u001b[32mStationary\\u001b[0m\")\n",
    "    else:\n",
    "        print(\"\\x1b[31mNon-stationary\\x1b[0m\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Augmented Dickey-Fuller Test on \"0\" \n",
      "    -----------------------------------------------\n",
      "ADF Statistic: -16.960872\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.431\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n",
      "\u001b[32mStationary\u001b[0m\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"1\" \n",
      "    -----------------------------------------------\n",
      "ADF Statistic: -17.412301\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.431\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n",
      "\u001b[32mStationary\u001b[0m\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"2\" \n",
      "    -----------------------------------------------\n",
      "ADF Statistic: -16.064493\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.431\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n",
      "\u001b[32mStationary\u001b[0m\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"3\" \n",
      "    -----------------------------------------------\n",
      "ADF Statistic: -10.494190\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.431\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n",
      "\u001b[32mStationary\u001b[0m\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"4\" \n",
      "    -----------------------------------------------\n",
      "ADF Statistic: -10.662284\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.431\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n",
      "\u001b[32mStationary\u001b[0m\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"5\" \n",
      "    -----------------------------------------------\n",
      "ADF Statistic: -16.591697\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.431\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n",
      "\u001b[32mStationary\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for country in data.country.unique():\n",
    "    filtered = data[data['country'] == country]\n",
    "    print(f'    Augmented Dickey-Fuller Test on \"{country}\"', \"\\n   \", '-'*47)\n",
    "\n",
    "    check_stationarity(filtered[['num_sold']])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train= train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['country'] = le.fit_transform(data['country'])\n",
    "data['store'] = le.fit_transform(data['store'])\n",
    "data['product'] = le.fit_transform(data['product'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,0,2)(1,0,1)[4] intercept   : AIC=3543444.748, Time=32.00 sec\n",
      " ARIMA(0,0,0)(0,0,0)[4] intercept   : AIC=3510886.296, Time=34.77 sec\n",
      " ARIMA(1,0,0)(1,0,0)[4] intercept   : AIC=3477199.268, Time=18.75 sec\n",
      " ARIMA(0,0,1)(0,0,1)[4] intercept   : AIC=3463564.924, Time=19.99 sec\n",
      " ARIMA(0,0,0)(0,0,0)[4]             : AIC=6014262.827, Time=4.21 sec\n",
      " ARIMA(0,0,1)(0,0,0)[4] intercept   : AIC=3461879.060, Time=29.68 sec\n",
      " ARIMA(0,0,1)(1,0,0)[4] intercept   : AIC=3479523.030, Time=16.68 sec\n",
      " ARIMA(0,0,1)(1,0,1)[4] intercept   : AIC=3463594.167, Time=22.81 sec\n",
      " ARIMA(1,0,1)(0,0,0)[4] intercept   : AIC=3457573.047, Time=57.66 sec\n",
      " ARIMA(1,0,1)(1,0,0)[4] intercept   : AIC=3477328.645, Time=21.08 sec\n",
      " ARIMA(1,0,1)(0,0,1)[4] intercept   : AIC=3459436.909, Time=22.61 sec\n",
      " ARIMA(1,0,1)(1,0,1)[4] intercept   : AIC=3460055.761, Time=24.85 sec\n",
      " ARIMA(1,0,0)(0,0,0)[4] intercept   : AIC=3457573.392, Time=54.98 sec\n",
      " ARIMA(2,0,1)(0,0,0)[4] intercept   : AIC=3519330.292, Time=15.90 sec\n",
      " ARIMA(1,0,2)(0,0,0)[4] intercept   : AIC=3528305.483, Time=17.71 sec\n",
      " ARIMA(0,0,2)(0,0,0)[4] intercept   : AIC=3461318.366, Time=24.89 sec\n",
      " ARIMA(2,0,0)(0,0,0)[4] intercept   : AIC=3457570.313, Time=41.07 sec\n",
      " ARIMA(2,0,0)(1,0,0)[4] intercept   : AIC=3477313.462, Time=21.47 sec\n",
      " ARIMA(2,0,0)(0,0,1)[4] intercept   : AIC=3459431.080, Time=20.61 sec\n",
      " ARIMA(2,0,0)(1,0,1)[4] intercept   : AIC=3460051.359, Time=23.66 sec\n",
      " ARIMA(3,0,0)(0,0,0)[4] intercept   : AIC=3455550.882, Time=60.56 sec\n",
      " ARIMA(3,0,0)(1,0,0)[4] intercept   : AIC=3479021.204, Time=27.90 sec\n",
      " ARIMA(3,0,0)(0,0,1)[4] intercept   : AIC=3458148.803, Time=22.39 sec\n",
      " ARIMA(3,0,0)(1,0,1)[4] intercept   : AIC=3458956.055, Time=30.09 sec\n",
      " ARIMA(3,0,1)(0,0,0)[4] intercept   : AIC=3519327.668, Time=19.45 sec\n",
      " ARIMA(3,0,0)(0,0,0)[4]             : AIC=3456027.921, Time=65.62 sec\n",
      "\n",
      "Best model:  ARIMA(3,0,0)(0,0,0)[4] intercept\n",
      "Total fit time: 751.445 seconds\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:               221259\n",
      "Model:               SARIMAX(3, 0, 0)   Log Likelihood            -1727766.441\n",
      "Date:                Fri, 31 Jan 2025   AIC                        3455550.882\n",
      "Time:                        18:27:34   BIC                        3455643.646\n",
      "Sample:                             0   HQIC                       3455578.066\n",
      "                             - 221259                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept     20.9993      3.954      5.311      0.000      13.250      28.748\n",
      "id             0.0004   4.27e-05      9.583      0.000       0.000       0.000\n",
      "country       92.4787      1.432     64.560      0.000      89.671      95.286\n",
      "store        274.0446      2.400    114.194      0.000     269.341     278.748\n",
      "product       56.3408      1.390     40.548      0.000      53.617      59.064\n",
      "ar.L1          0.4665      0.002    188.603      0.000       0.462       0.471\n",
      "ar.L2         -0.0487      0.003    -14.528      0.000      -0.055      -0.042\n",
      "ar.L3          0.0964      0.003     30.319      0.000       0.090       0.103\n",
      "sigma2      3.553e+05      0.006    5.9e+07      0.000    3.55e+05    3.55e+05\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                  66.59   Jarque-Bera (JB):            387890.12\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.74   Skew:                             1.90\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                         8.26\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "[2] Covariance matrix is singular or near-singular, with condition number 1.35e+21. Standard errors may be unstable.\n",
      "<bound method ARIMA.params of ARIMA(maxiter=2, order=(3, 0, 0), scoring_args={}, seasonal_order=(0, 0, 0, 4),\n",
      "      suppress_warnings=True)>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(arima\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(arima\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m---> 13\u001b[0m pred\u001b[38;5;241m=\u001b[39marima\u001b[38;5;241m.\u001b[39mpredict(n_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[43mtest\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeantemp\u001b[39m\u001b[38;5;124m'\u001b[39m]), alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[0;32m     14\u001b[0m pred\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Evaluation \n",
    "data = data.dropna()\n",
    "# Fit a simple auto_arima model\n",
    "arima = pm.auto_arima(data['num_sold'],X=data.drop(columns=['num_sold']), d=2,error_action='ignore', trace=True,\n",
    "                      suppress_warnings=True, maxiter=2,m=4,stationary=True,test='adf')\n",
    "\n",
    "# Print out summary information on the fit\n",
    "print(arima.summary())\n",
    "print(arima.params)\n",
    "\n",
    "\n",
    "\n",
    "pred=arima.predict(n_periods=100, X=test.drop(columns=['date','meantemp']), alpha=0.05)\n",
    "pred\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.grid()\n",
    "#plt.plot(data['Period'][:-10], train['GDP_GROWTH'], marker='o', label='Train')\n",
    "plt.plot(train['date'][-100:],bli['meantemp'], marker='o', label='Test')\n",
    "plt.plot(train['date'][-100:],pred, marker='v', label='Prediction')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "print(\"=\"*50)\n",
    "print(\"=\"*50)\n",
    "mape=mean_absolute_percentage_error(test['meantemp'], pred)\n",
    "print(\"Mean Absolute Percentage Error\", mape)\n",
    "print(\"=\"*50)\n",
    "mse=mean_squared_error(test['meantemp'], pred)\n",
    "print(\"Mean Squared Error\",mse)\n",
    "print(\"=\"*50)\n",
    "print(\"RMSE\", (mse)**0.5)\n",
    "print(\"=\"*50)\n",
    "print(\"AIC values {}\".format(arima.aic()))\n",
    "print(\"=\"*50)\n",
    "print(\"=\"*50)\n",
    "print(\"=\"*50)\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "a=pd.DataFrame(test['meantemp'])\n",
    "a=a.reset_index()\n",
    "a=a.drop(columns='index')\n",
    "a\n",
    "\n",
    "prediction=pd.DataFrame(pred)\n",
    "prediction=prediction.reset_index()\n",
    "prediction=prediction.drop(columns='index')\n",
    "prediction\n",
    "output=pd.DataFrame()\n",
    "output['Test']=a['meantemp']\n",
    "output['Prediction']=prediction[0]\n",
    "output['Difference']=output['Test']-output['Prediction']\n",
    "output['% Chnage']=abs(output['Difference']/output['Test'])*100\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Fit ARIMA models for each category\n",
    "categories = train['country'].unique()  # Assuming 'category' is the name of the categorical column\n",
    "for category in categories:\n",
    "    category_data = data[data['category'] == category]['value']\n",
    "    \n",
    "    # Fit the ARIMA model\n",
    "    model = ARIMA(category_data, order=(5, 1, 0))  # Example order, adjust as necessary\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Save the trained model\n",
    "    joblib.dump(model_fit, f'models/trained_model_{category}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
