{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LogitRegression' from 'sklearn.linear_model' (c:\\Users\\Leo\\.pyenv\\pyenv-win-venv\\envs\\venv_kaggle\\lib\\site-packages\\sklearn\\linear_model\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mydata_profiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogitRegression\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcb\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscalecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mForecaster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Forecaster\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LogitRegression' from 'sklearn.linear_model' (c:\\Users\\Leo\\.pyenv\\pyenv-win-venv\\envs\\venv_kaggle\\lib\\site-packages\\sklearn\\linear_model\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import holidays \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import catboost as cb\n",
    "from scalecast.Forecaster import Forecaster\n",
    "\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "\n",
    "import time\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.date(2025, 1, 1): \"New Year's Day\", datetime.date(2025, 5, 26): 'Memorial Day', datetime.date(2025, 6, 19): 'Juneteenth National Independence Day', datetime.date(2025, 7, 4): 'Independence Day', datetime.date(2025, 9, 1): 'Labor Day', datetime.date(2025, 11, 11): 'Veterans Day', datetime.date(2025, 11, 27): 'Thanksgiving', datetime.date(2025, 12, 25): 'Christmas Day', datetime.date(2025, 1, 20): 'Martin Luther King Jr. Day', datetime.date(2025, 2, 17): \"Washington's Birthday\", datetime.date(2025, 10, 13): 'Columbus Day'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "holidays.US(years=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "blind = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_holiday(row):\n",
    "    \"\"\"\n",
    "    Determines if a given date is a holiday in the specified country.\n",
    "    Optimized for Canada, Finland, and Italy.\n",
    "    \n",
    "    Parameters:\n",
    "    row: pandas Series containing 'country' and 'date' columns\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if the date is a holiday in the given country, False otherwise\n",
    "    \"\"\"\n",
    "    country = row['country']\n",
    "    date = pd.to_datetime(row['date']).date()  # Convert to date only\n",
    "\n",
    "    country_mapping = {\n",
    "        'Canada': holidays.CA(),\n",
    "        'Finland': holidays.FI(),\n",
    "        'Italy': holidays.IT(), \n",
    "        'Kenya': holidays.KE(),\n",
    "        'Norway': holidays.NO(),\n",
    "        'Singapore': holidays.SG(),\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Get the holidays object for the country\n",
    "        if country in country_mapping:\n",
    "            country_holidays = country_mapping[country]\n",
    "            return date in country_holidays\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking holiday for {country} on {date}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Create a cache of holiday objects to improve performance\n",
    "def initialize_holiday_detection(df):\n",
    "    \"\"\"\n",
    "    Initialize holiday detection by creating holiday objects for all unique years in the dataset.\n",
    "    This improves performance by avoiding repeated creation of holiday objects.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame containing 'date' column\n",
    "    \"\"\"\n",
    "    years = pd.to_datetime(df['date']).dt.year.unique()\n",
    "    holiday_cache = {\n",
    "        'Canada': {year: holidays.CA(years=year) for year in years},\n",
    "        'Finland': {year: holidays.FI(years=year) for year in years},\n",
    "        'Italy': {year: holidays.IT(years=year) for year in years}, \n",
    "        'Kenya': {year: holidays.KE(years=year) for year in years},\n",
    "        'Norway': {year: holidays.NO(years=year) for year in years},\n",
    "        'Singapore': {year: holidays.SG(years=year) for year in years}\n",
    "\n",
    "    }\n",
    "    \n",
    "    def is_holiday_cached(row):\n",
    "        country = row['country']\n",
    "        date = pd.to_datetime(row['date']).date()\n",
    "        year = date.year\n",
    "        \n",
    "        try:\n",
    "            if country in holiday_cache:\n",
    "                return date in holiday_cache[country][year]\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking holiday for {country} on {date}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    return is_holiday_cached\n",
    "\n",
    "# Example usage:\n",
    "# First initialize the cached version\n",
    "holiday_checker = initialize_holiday_detection(train)\n",
    "\n",
    "# Then apply it to create the holiday flag\n",
    "train['is_holiday'] = train.apply(holiday_checker, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (195610, 18)\n",
      "y_train shape: (195610,)\n",
      "X_test shape: (34520, 18)\n",
      "y_test shape: (34520,)\n"
     ]
    }
   ],
   "source": [
    "def feature_eng(df):\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Extract date features\n",
    "    \n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "    # Encode categorical features\n",
    "    # Drop missing values and irrelevant columns\n",
    "    imputer = SimpleImputer(strategy=\"mean\")  # Change to \"mean\", \"most_frequent\", or \"constant\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df = df.set_index('id')\n",
    "    df = df.drop(columns=['date'])  # Dropping columns that are not useful for modeling\n",
    "    # Separate features and target\n",
    "    try: \n",
    "        df[\"num_sold\"] = imputer.fit_transform(df[[\"num_sold\"]])\n",
    "       # df[\"num_sold\"] = scaler.fit_transform(df[[\"num_sold\"]])\n",
    "\n",
    "    except: pass\n",
    "    try: \n",
    "        X = df.drop(columns=['num_sold'])\n",
    "        X = pd.get_dummies(X)\n",
    "\n",
    "    except:\n",
    "        X=pd.get_dummies(df)\n",
    "    try:\n",
    "        y = df['num_sold']\n",
    "    except:\n",
    "        y = None\n",
    "    # Scale features\n",
    "    #X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    return df, X,  y\n",
    "\n",
    "# Feature engineering\n",
    "df, X, y = feature_eng(train)\n",
    "\n",
    "# Splitting the data\n",
    "SPLIT = 0.85\n",
    "split_index = int(SPLIT * len(X))\n",
    "\n",
    "X_train = X[:split_index]\n",
    "y_train = y[:split_index]\n",
    "X_test = X[split_index:]\n",
    "y_test = y[split_index:]\n",
    "\n",
    "# Verify shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>country_Canada</th>\n",
       "      <th>country_Finland</th>\n",
       "      <th>country_Italy</th>\n",
       "      <th>country_Kenya</th>\n",
       "      <th>country_Norway</th>\n",
       "      <th>country_Singapore</th>\n",
       "      <th>store_Discount Stickers</th>\n",
       "      <th>store_Premium Sticker Mart</th>\n",
       "      <th>store_Stickers for Less</th>\n",
       "      <th>product_Holographic Goose</th>\n",
       "      <th>product_Kaggle</th>\n",
       "      <th>product_Kaggle Tiers</th>\n",
       "      <th>product_Kerneler</th>\n",
       "      <th>product_Kerneler Dark Mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195605</th>\n",
       "      <td>False</td>\n",
       "      <td>348</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195606</th>\n",
       "      <td>False</td>\n",
       "      <td>348</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195607</th>\n",
       "      <td>False</td>\n",
       "      <td>348</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195608</th>\n",
       "      <td>False</td>\n",
       "      <td>348</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195609</th>\n",
       "      <td>False</td>\n",
       "      <td>348</td>\n",
       "      <td>12</td>\n",
       "      <td>2015</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195610 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_holiday  day_of_year  month  year  country_Canada  country_Finland  \\\n",
       "id                                                                              \n",
       "0             True            1      1  2010            True            False   \n",
       "1             True            1      1  2010            True            False   \n",
       "2             True            1      1  2010            True            False   \n",
       "3             True            1      1  2010            True            False   \n",
       "4             True            1      1  2010            True            False   \n",
       "...            ...          ...    ...   ...             ...              ...   \n",
       "195605       False          348     12  2015           False            False   \n",
       "195606       False          348     12  2015           False            False   \n",
       "195607       False          348     12  2015           False            False   \n",
       "195608       False          348     12  2015           False            False   \n",
       "195609       False          348     12  2015           False            False   \n",
       "\n",
       "        country_Italy  country_Kenya  country_Norway  country_Singapore  \\\n",
       "id                                                                        \n",
       "0               False          False           False              False   \n",
       "1               False          False           False              False   \n",
       "2               False          False           False              False   \n",
       "3               False          False           False              False   \n",
       "4               False          False           False              False   \n",
       "...               ...            ...             ...                ...   \n",
       "195605           True          False           False              False   \n",
       "195606           True          False           False              False   \n",
       "195607           True          False           False              False   \n",
       "195608           True          False           False              False   \n",
       "195609           True          False           False              False   \n",
       "\n",
       "        store_Discount Stickers  store_Premium Sticker Mart  \\\n",
       "id                                                            \n",
       "0                          True                       False   \n",
       "1                          True                       False   \n",
       "2                          True                       False   \n",
       "3                          True                       False   \n",
       "4                          True                       False   \n",
       "...                         ...                         ...   \n",
       "195605                    False                       False   \n",
       "195606                    False                       False   \n",
       "195607                    False                       False   \n",
       "195608                    False                       False   \n",
       "195609                    False                       False   \n",
       "\n",
       "        store_Stickers for Less  product_Holographic Goose  product_Kaggle  \\\n",
       "id                                                                           \n",
       "0                         False                       True           False   \n",
       "1                         False                      False            True   \n",
       "2                         False                      False           False   \n",
       "3                         False                      False           False   \n",
       "4                         False                      False           False   \n",
       "...                         ...                        ...             ...   \n",
       "195605                     True                       True           False   \n",
       "195606                     True                      False            True   \n",
       "195607                     True                      False           False   \n",
       "195608                     True                      False           False   \n",
       "195609                     True                      False           False   \n",
       "\n",
       "        product_Kaggle Tiers  product_Kerneler  product_Kerneler Dark Mode  \n",
       "id                                                                          \n",
       "0                      False             False                       False  \n",
       "1                      False             False                       False  \n",
       "2                       True             False                       False  \n",
       "3                      False              True                       False  \n",
       "4                      False             False                        True  \n",
       "...                      ...               ...                         ...  \n",
       "195605                 False             False                       False  \n",
       "195606                 False             False                       False  \n",
       "195607                  True             False                       False  \n",
       "195608                 False              True                       False  \n",
       "195609                 False             False                        True  \n",
       "\n",
       "[195610 rows x 18 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0         752.527382\n",
       "1         973.000000\n",
       "2         906.000000\n",
       "3         423.000000\n",
       "4         491.000000\n",
       "             ...    \n",
       "195605    150.000000\n",
       "195606    874.000000\n",
       "195607    717.000000\n",
       "195608    453.000000\n",
       "195609    438.000000\n",
       "Name: num_sold, Length: 195610, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "195610     170.0\n",
       "195611    1047.0\n",
       "195612     981.0\n",
       "195613     513.0\n",
       "195614     492.0\n",
       "           ...  \n",
       "230125     466.0\n",
       "230126    2907.0\n",
       "230127    2299.0\n",
       "230128    1242.0\n",
       "230129    1622.0\n",
       "Name: num_sold, Length: 34520, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 248.1475\n",
      "MAPE: 3.0422\n",
      "Mean Squared Error: 118420.2639\n",
      "R-squared: 0.6478\n",
      "Coefficients: [ 3.77165272e+01  8.10233613e-02 -3.42425231e+00 -6.81727755e+00\n",
      "  7.79357301e+01 -9.81025856e+00 -2.14775054e+02 -6.50285148e+02\n",
      "  7.08026730e+02  8.89080004e+01 -3.08593593e+02  2.22084217e+02\n",
      "  8.65093759e+01 -4.56236057e+02  4.90390358e+02  2.69673676e+02\n",
      " -1.99475825e+02 -1.04352152e+02]\n",
      "Intercept: 14490.864200642352\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using training data\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test.values)\n",
    "\n",
    "# Evaluate the model using common metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"MAPE: {mape:.4f}\")\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "\n",
    "# Optionally: You can get the coefficients and intercept of the linear regression model\n",
    "print(f\"Coefficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 13:26:17,001] A new study created in memory with name: no-name-ab083a5c-0b07-4b12-ba43-df4ce3f5a67e\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a84edd58df545ae9d9a9e99fd0bd629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Starting Trial 1 out of 15\n",
      "✅ Trial 1 completed in 2.7s\n",
      "   MAPE: 1.8820, MAE: 110.6834, RMSE: 147.2241\n",
      "[I 2025-01-30 13:26:19,756] Trial 0 finished with value: 1.8819735792729888 and parameters: {'n_estimators': 76, 'learning_rate': 0.021529971531891543, 'max_depth': 15, 'subsample': 0.9551041287765066, 'colsample_bytree': 0.9948239312763494, 'reg_alpha': 6.937097660895436, 'reg_lambda': 0.3382793882593333, 'min_child_weight': 2, 'gamma': 2.248265238783105}. Best is trial 0 with value: 1.8819735792729888.\n",
      "🔄 Starting Trial 2 out of 15\n",
      "✅ Trial 2 completed in 3.6s\n",
      "   MAPE: 0.6619, MAE: 75.7065, RMSE: 120.6409\n",
      "[I 2025-01-30 13:26:23,392] Trial 1 finished with value: 0.6618970142189052 and parameters: {'n_estimators': 204, 'learning_rate': 0.04510335348442594, 'max_depth': 15, 'subsample': 0.8138140076129938, 'colsample_bytree': 0.5445631689210862, 'reg_alpha': 0.6993973423962253, 'reg_lambda': 5.868284764973139, 'min_child_weight': 5, 'gamma': 1.67479363594156}. Best is trial 1 with value: 0.6618970142189052.\n",
      "🔄 Starting Trial 3 out of 15\n",
      "✅ Trial 3 completed in 2.5s\n",
      "   MAPE: 0.4938, MAE: 71.4803, RMSE: 118.2657\n",
      "[I 2025-01-30 13:26:25,915] Trial 2 finished with value: 0.49384729822835427 and parameters: {'n_estimators': 180, 'learning_rate': 0.03813295073621798, 'max_depth': 9, 'subsample': 0.9191724185897566, 'colsample_bytree': 0.7075452033996124, 'reg_alpha': 5.947573415616664, 'reg_lambda': 1.2378338339639383, 'min_child_weight': 1, 'gamma': 1.0615367596491594}. Best is trial 2 with value: 0.49384729822835427.\n",
      "🔄 Starting Trial 4 out of 15\n",
      "✅ Trial 4 completed in 4.3s\n",
      "   MAPE: 0.9795, MAE: 81.8204, RMSE: 117.7389\n",
      "[I 2025-01-30 13:26:30,233] Trial 3 finished with value: 0.9794565973458151 and parameters: {'n_estimators': 157, 'learning_rate': 0.017973853047482086, 'max_depth': 17, 'subsample': 0.6607822382030206, 'colsample_bytree': 0.800396421194207, 'reg_alpha': 0.22246301609765964, 'reg_lambda': 3.3530329039792144, 'min_child_weight': 3, 'gamma': 1.8742756534231697}. Best is trial 2 with value: 0.49384729822835427.\n",
      "🔄 Starting Trial 5 out of 15\n",
      "✅ Trial 5 completed in 1.8s\n",
      "   MAPE: 0.7344, MAE: 77.8177, RMSE: 120.6977\n",
      "[I 2025-01-30 13:26:32,032] Trial 4 finished with value: 0.7344324690365572 and parameters: {'n_estimators': 187, 'learning_rate': 0.08153631904086102, 'max_depth': 5, 'subsample': 0.8318067143841206, 'colsample_bytree': 0.7449320440824349, 'reg_alpha': 1.2346258043521456, 'reg_lambda': 0.11807827311923218, 'min_child_weight': 5, 'gamma': 0.13688634765875174}. Best is trial 2 with value: 0.49384729822835427.\n",
      "🔄 Starting Trial 6 out of 15\n",
      "✅ Trial 6 completed in 7.1s\n",
      "   MAPE: 0.6903, MAE: 77.1605, RMSE: 120.7617\n",
      "[I 2025-01-30 13:26:39,203] Trial 5 finished with value: 0.6902788147058586 and parameters: {'n_estimators': 366, 'learning_rate': 0.019929315219518774, 'max_depth': 16, 'subsample': 0.8674275833508148, 'colsample_bytree': 0.5214013300809219, 'reg_alpha': 0.5864066958672743, 'reg_lambda': 2.633084376049268, 'min_child_weight': 6, 'gamma': 3.051021879934173}. Best is trial 2 with value: 0.49384729822835427.\n",
      "🔄 Starting Trial 7 out of 15\n",
      "✅ Trial 7 completed in 2.9s\n",
      "   MAPE: 0.7347, MAE: 80.7682, RMSE: 120.0548\n",
      "[I 2025-01-30 13:26:42,099] Trial 6 finished with value: 0.7346758200023835 and parameters: {'n_estimators': 157, 'learning_rate': 0.03011831189696193, 'max_depth': 11, 'subsample': 0.8132847245378575, 'colsample_bytree': 0.6023218731100288, 'reg_alpha': 0.88475967496178, 'reg_lambda': 2.211612218064528, 'min_child_weight': 3, 'gamma': 0.301509607164272}. Best is trial 2 with value: 0.49384729822835427.\n",
      "🔄 Starting Trial 8 out of 15\n",
      "✅ Trial 8 completed in 2.4s\n",
      "   MAPE: 1.1287, MAE: 114.9067, RMSE: 159.9749\n",
      "[I 2025-01-30 13:26:44,526] Trial 7 finished with value: 1.1286907731365425 and parameters: {'n_estimators': 202, 'learning_rate': 0.0245127127304165, 'max_depth': 4, 'subsample': 0.5157720153501034, 'colsample_bytree': 0.5704038118742857, 'reg_alpha': 2.8843772598706834, 'reg_lambda': 2.6323858247868017, 'min_child_weight': 2, 'gamma': 3.1938001992329506}. Best is trial 2 with value: 0.49384729822835427.\n",
      "🔄 Starting Trial 9 out of 15\n",
      "✅ Trial 9 completed in 7.8s\n",
      "   MAPE: 0.6199, MAE: 74.6019, RMSE: 121.4384\n",
      "[I 2025-01-30 13:26:52,348] Trial 8 finished with value: 0.6198550822657629 and parameters: {'n_estimators': 402, 'learning_rate': 0.03004745460257961, 'max_depth': 13, 'subsample': 0.9358534914780019, 'colsample_bytree': 0.5239938651387029, 'reg_alpha': 0.12606000530894915, 'reg_lambda': 0.1344639470179681, 'min_child_weight': 7, 'gamma': 2.6408720023314807}. Best is trial 2 with value: 0.49384729822835427.\n",
      "🔄 Starting Trial 10 out of 15\n",
      "✅ Trial 10 completed in 2.7s\n",
      "   MAPE: 0.5243, MAE: 73.5543, RMSE: 118.8696\n",
      "[I 2025-01-30 13:26:55,087] Trial 9 finished with value: 0.524256780203395 and parameters: {'n_estimators': 200, 'learning_rate': 0.024427311034822152, 'max_depth': 8, 'subsample': 0.5020937597192587, 'colsample_bytree': 0.8278542807918776, 'reg_alpha': 0.8300949465336388, 'reg_lambda': 0.4369626475582433, 'min_child_weight': 7, 'gamma': 4.899118764676277}. Best is trial 2 with value: 0.49384729822835427.\n",
      "🔄 Starting Trial 11 out of 15\n",
      "✅ Trial 11 completed in 1.5s\n",
      "   MAPE: 0.4860, MAE: 72.4366, RMSE: 119.2466\n",
      "[I 2025-01-30 13:26:56,601] Trial 10 finished with value: 0.4859836545384457 and parameters: {'n_estimators': 499, 'learning_rate': 0.16795930695649613, 'max_depth': 8, 'subsample': 0.6900371913840349, 'colsample_bytree': 0.674042831529599, 'reg_alpha': 9.306670679632813, 'reg_lambda': 0.9157015542315128, 'min_child_weight': 1, 'gamma': 0.959069323184222}. Best is trial 10 with value: 0.4859836545384457.\n",
      "🔄 Starting Trial 12 out of 15\n",
      "✅ Trial 12 completed in 1.6s\n",
      "   MAPE: 0.4840, MAE: 72.3886, RMSE: 118.8324\n",
      "[I 2025-01-30 13:26:58,169] Trial 11 finished with value: 0.48404383528174444 and parameters: {'n_estimators': 498, 'learning_rate': 0.1317538755958626, 'max_depth': 8, 'subsample': 0.6718151110275, 'colsample_bytree': 0.6808988822240054, 'reg_alpha': 9.999495135116257, 'reg_lambda': 0.8914800287483365, 'min_child_weight': 1, 'gamma': 1.0349073492086378}. Best is trial 11 with value: 0.48404383528174444.\n",
      "🔄 Starting Trial 13 out of 15\n",
      "✅ Trial 13 completed in 2.1s\n",
      "   MAPE: 0.5549, MAE: 74.2715, RMSE: 118.7216\n",
      "[I 2025-01-30 13:27:00,311] Trial 12 finished with value: 0.5549072510136214 and parameters: {'n_estimators': 475, 'learning_rate': 0.16105153030730873, 'max_depth': 7, 'subsample': 0.6830564048949852, 'colsample_bytree': 0.6545482280179679, 'reg_alpha': 9.768635297906089, 'reg_lambda': 0.7035735456249832, 'min_child_weight': 1, 'gamma': 1.0089987492160324}. Best is trial 11 with value: 0.48404383528174444.\n",
      "🔄 Starting Trial 14 out of 15\n",
      "✅ Trial 14 completed in 1.7s\n",
      "   MAPE: 0.4655, MAE: 73.4004, RMSE: 120.9276\n",
      "[I 2025-01-30 13:27:02,032] Trial 13 finished with value: 0.4654791538551022 and parameters: {'n_estimators': 499, 'learning_rate': 0.19778851749512344, 'max_depth': 11, 'subsample': 0.6489641178002785, 'colsample_bytree': 0.655315372397282, 'reg_alpha': 3.0543253555971366, 'reg_lambda': 1.021231997226768, 'min_child_weight': 1, 'gamma': 1.1318890719176682}. Best is trial 13 with value: 0.4654791538551022.\n",
      "🔄 Starting Trial 15 out of 15\n",
      "✅ Trial 15 completed in 2.3s\n",
      "   MAPE: 0.4122, MAE: 71.3145, RMSE: 120.3774\n",
      "[I 2025-01-30 13:27:04,296] Trial 14 finished with value: 0.41220602696209513 and parameters: {'n_estimators': 403, 'learning_rate': 0.10554195700542933, 'max_depth': 11, 'subsample': 0.6043146963145078, 'colsample_bytree': 0.8605305287890477, 'reg_alpha': 2.826701499971443, 'reg_lambda': 0.29056594232473903, 'min_child_weight': 3, 'gamma': 4.107574494727228}. Best is trial 14 with value: 0.41220602696209513.\n",
      "\n",
      "🏆 Best Trial Results:\n",
      "MAPE: 0.4122\n",
      "Best Parameters: {'n_estimators': 403, 'learning_rate': 0.10554195700542933, 'max_depth': 11, 'subsample': 0.6043146963145078, 'colsample_bytree': 0.8605305287890477, 'reg_alpha': 2.826701499971443, 'reg_lambda': 0.29056594232473903, 'min_child_weight': 3, 'gamma': 4.107574494727228, 'enable_categorical': True, 'device': 'cpu', 'tree_method': 'auto'}\n",
      "Final MAPE: 0.4955\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, X_test, y_train, y_test, total_trials):\n",
    "    \"\"\"\n",
    "    Optuna objective function for XGBoost hyperparameter optimization with GPU support.\n",
    "    \n",
    "    Parameters:\n",
    "    trial: Optuna trial object\n",
    "    X_train, X_test, y_train, y_test: Training and test data\n",
    "    total_trials: Total number of trials to run\n",
    "    \"\"\"\n",
    "    trial_start = time.time()\n",
    "    print(f\"🔄 Starting Trial {trial.number + 1} out of {total_trials}\")\n",
    "    \n",
    "    # Check GPU availability\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    device = \"gpu\" if gpu_available else \"cpu\"\n",
    "    tree_method = \"hist\" if gpu_available else \"auto\"\n",
    "    \n",
    "    # Define hyperparameters with reasonable ranges\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 18),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.1, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.1, 10.0, log=True),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 7),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"device\": device,\n",
    "        \"tree_method\": tree_method\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Convert data to device-appropriate format\n",
    "        if device == \"gpu\":\n",
    "            X_train_device = xgb.DMatrix(X_train, y_train)\n",
    "            X_test_device = xgb.DMatrix(X_test)\n",
    "        else:\n",
    "            X_train_device = X_train\n",
    "            X_test_device = X_test\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        model = xgb.XGBRegressor(\n",
    "            **param,\n",
    "            early_stopping_rounds=50,\n",
    "            eval_metric=['mae', 'mape']\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_device, y_train,\n",
    "            eval_set=[(X_test_device, y_test)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        preds = model.predict(X_test_device)\n",
    "        mape = mean_absolute_percentage_error(y_test, preds)\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        mae = np.mean(np.abs(y_test - preds))\n",
    "        rmse = np.sqrt(np.mean((y_test - preds) ** 2))\n",
    "        \n",
    "        # Log results\n",
    "        trial.set_user_attr('mae', mae)\n",
    "        trial.set_user_attr('rmse', rmse)\n",
    "        trial.set_user_attr('n_estimators_used', model.best_iteration or param['n_estimators'])\n",
    "        \n",
    "        trial_time = time.time() - trial_start\n",
    "        print(f\"✅ Trial {trial.number + 1} completed in {trial_time:.1f}s\")\n",
    "        print(f\"   MAPE: {mape:.4f}, MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "        \n",
    "        return mape\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Trial {trial.number + 1} failed: {str(e)}\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "def run_optimization(X_train, X_test, y_train, y_test, n_trials=5):\n",
    "    \"\"\"\n",
    "    Run the complete optimization process and return the best model.\n",
    "    \"\"\"\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    \n",
    "    try:\n",
    "        study.optimize(\n",
    "            lambda trial: objective(trial, X_train, X_test, y_train, y_test, n_trials),\n",
    "            n_trials=n_trials,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # Get best parameters and create final model\n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            \"enable_categorical\": True,\n",
    "            \"device\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "            \"tree_method\": \"hist\" if torch.cuda.is_available() else \"auto\"\n",
    "        })\n",
    "        \n",
    "        best_model = xgb.XGBRegressor(**best_params)\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"\\n🏆 Best Trial Results:\")\n",
    "        print(f\"MAPE: {study.best_value:.4f}\")\n",
    "        print(\"Best Parameters:\", best_params)\n",
    "        \n",
    "        return best_model, study\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⚠️ Optimization interrupted by user\")\n",
    "        return None, study\n",
    "\n",
    "\n",
    "best_model, study = run_optimization(X_train, X_test, y_train, y_test, n_trials=15)\n",
    "\n",
    "# Make predictions with best model\n",
    "if best_model is not None:\n",
    "    predictions = best_model.predict(X_test)\n",
    "    final_mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    print(f\"Final MAPE: {final_mape:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_checker = initialize_holiday_detection(blind)\n",
    "blind['is_holiday'] =blind.apply(holiday_checker, axis=1)\n",
    "X_trial = feature_eng(blind)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_trial)\n",
    "submission_df = pd.DataFrame({\"predictions\": predictions})\n",
    "submission_df = pd.merge(blind['id'], \n",
    "         submission_df,\n",
    "         left_index=True,\n",
    "         right_index=True)\n",
    "submission_file = submission_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 731.68994,  672.5833 ,  554.0756 , ..., 1995.6849 , 1142.4535 ,\n",
       "       1370.7294 ], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
